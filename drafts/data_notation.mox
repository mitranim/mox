;;
## Data Notation

Our language has "levels". The first level defines a "data notation": literal
syntax for various primitive types and nestable blocks. This level is not aware
of any language specifics.

This concept is fundamentally inspired by the idea, which has been proven and
demonstrated in practice, that programming languages greatly benefit from being
defined in terms of a foundational data notation, and NOT in terms of character
sequences, reserved keywords, or similar.

This is conceptually and syntactically similar to Clojure's EDN.

Editors should implement a simplified syntax highlighter for the data
notation, independent of any language or configuration defined in it.
This could be useful for future DSLs.

The provided tooling must include a parser and a formatter.

The parser must preserve comments. This is essential for code formatting,
generating documentation, or automatically editing configuration files.

The parser must preserve enough information for automatic code formatting and
rewriting. This may require preserving all whitespace, or at least the counts
of subsequent newlines. Non-whitespace tokens must be printable back exactly
as they were written.

The parser API should include an option to parse exactly one syntactic form
out of the input, instead of the entire input; could be useful for embedding
this notation in some other syntax.

This notation is defined in terms of Unicode characters, independently of any
text encoding. Specific parser implementations may restrict input to UTF-8
text. Specific language implementations may restrict literal strings to UTF-8.

This notation currently doesn't define a way to embed binary data.
It's possible instead to use base64 strings or simply lists of numbers.
;;

;;;;;
## Comments

Comments begin and end with semicolon fences, and are always multi-line.
The fences must match. Fences are at least 2-semicolon long, but can be
extended indefinitely to allow nesting. The following are all valid:

  ;; comment ;;

  ;;; comment ;;;

  ;;;;
  comment
  ;;; embedded comment ;;;
  comment
  ;;;;

Comments may be used to generate documentation, following the conventions
established by Go, Swift, Rust. Comments should use Markdown. A comment
immediately followed by a named definition serves as the documentation for
that definition.

As mentioned above, comments must be preserved in the AST. If a language
defined in terms of this notation has an interpreted form with a REPL, the
docs generated from the comments might be made accessible in the REPL.
;;;;;

;;
## Numbers

Numbers should be parsed with unlimited precision, in order to support untyped
numeric constants and "big number" literals. Ideally, the AST should preserve
the original text for formatting (print back as-is).

The notation supports several radices.
Every radix allows integers and fractionals.

The Ne+N exponent notation is not supported for now.

Letters in number literals must be lowercase. Uppercase is reserved for
potential arbitrary-base exponents.

Number literals support a leading `-`, which is treated as a special case
distinct from operators. Leading `+` is currently a syntax error; support
may be added later.

There is no support for numeric suffixes seen in some languages,
like `123ul` in C. Numeric literals are untyped, like in Go.
;;

;; Binary ;;
0b01 0b01.01

;; Octal ;;
0o01234567 0o01234567.01234567

;; Hex ;;
0h0123456789abcdef 0h0123456789abcdef.0123456789abcdef

;; Decimal ;;
0123456789 0123456789.0123456789

;;
### Parsing Restrictions

The contents of comments and strings are exempt from all restrictions below.

To avoid ambiguities and reserve space for future extensions, the parser must
reject identifier characters immediately following a number, if they're not
valid digits for its radix. This automatically rejects unknown radix
specifiers, as they appear to be malformed decimals. This restriction must
also be applied immediately after a known radix specifier.

  0b012         -- Invalid: `2` is not a binary digit.
  0123456789_   -- Invalid: `_` is not a decimal digit.
  0123456789a   -- Invalid: `a` is not a decimal digit.
  0123456789e10 -- Invalid: `e` is not a decimal digit.
  0b            -- Invalid: missing digit after radix.
  0b2           -- Invalid: `2` is not a binary digit.
  0o            -- Invalid: missing digit after radix.
  0o8           -- Invalid: `8` is not an octal digit.
  0h            -- Invalid: missing digit after radix.
  0hg           -- Invalid: `g` is not a hex digit.
  0x            -- Invalid: missing digit after radix.

To avoid ambiguities, the parser must reject a dot immediately followed by a
decimal digit, except inside numeric literals.

  .0123456789   ; Invalid.
  ..0123456789  ; Invalid.
  ...0123456789 ; Invalid.
  . 0123456789  ; Valid.
  . abcdef      ; Valid.

To avoid ambiguities, the parser must reject a number ending with a dot which
is not immediately followed by a digit appropriate for its radix.

  0b01.         ; Invalid.
  0b01.2        ; Invalid.
  0123456789.   ; Invalid.
  0123456789.a  ; Invalid.

  0b01.0        ; Valid.
  0b01 .        ; Valid.
  0b01 . 2      ; Valid.
  0123456789.0  ; Valid.
  0123456789 .  ; Valid.
  0123456789 .a ; Valid.

### Characters

Character literals are currently not supported
because they're easily avodable.

One common approach is to define a function that takes a string and returns a
Unicode code point. Python example:

    ord("a") # 97

In a compiled language we could validate and evaluate this at compile time.
Thus, we avoid unnecessary syntax at no runtime cost. This approach is also
more flexible: you could define multiple functions, tailored for specific use
cases.

If we really wanted character literals, they could use dead syntactic space
in numeric literals, something like:

  0c_a -- Interpreted as 97 (lowercase "a").

...But string literals seem simpler.
;;

;;
## Strings

All string literals are multi-line. Single quotes are currently not supported
and generate a parse error.

All string literals support indefinitely resizable fences, similar to comments.
All of the following are valid:

  ""
  "str"
  ""str""
  """str"""
  """"str""""
  ``
  `str`
  ``str``
  ```str```
  ````str````

There's no special support for string interpolation. Languages defined in
terms of this notation may choose to implement some form of interpolation or
C-printf-like formatting via macros. The default recommended approach is to
provide a variadic function that collates a single string from its arguments.
;;

;;
Double-quoted strings are multiline, with indefinitely resizable fences,
and support character escape sequences.

Since code formatters need to be able to write code back as-is, a parser should
either store a reference to the source text in the resulting AST node, or treat
the string as raw without decoding the escapes.
;;
"
double-quoted string:
supports newlines and escapes: \t \n
"

;;
Backquoted strings are multiline, with indefinitely resizable fences,
and are raw, without any escape sequences.
;;
`
backquoted string:
supports newlines, but not escapes: \t \n
`

;;
## Symbols

Symbols are sequences of unquoted characters, and may include most printable
non-whitespace ASCII characters:

  ABCDEFGHIJKLMNOPQRSTUVWXYZ
  abcdefghijklmnopqrstuvwxyz
  0123456789
  ~ ! @ # $ % ^ & * : < > ? / \ | = + - _ .

Languages may define restrictions such as "identifiers" vs "operators".

The base level of notation doesn't define any meaning for any symbols.
In practice, data decoders and encoders would use a slightly higher level
specialization of the notation, closer to JSON, with support for the values
`nil` `false` `true` and dictionaries via `{}`.

Since numeric literals are syntactically a subset of symbols, the parser must
parse them first, and avoid syntactic ambiguity by rejecting immediately
adjacent numbers and symbols, with the special exception of leading `-`
before a number.

This notation doesn't support commas and discourages unnecessary punctuation.
Statements, expressions, elements in data structures, and arguments in
function calls rely on whitespace for separation.
;;

;;
Because "operators" and "identifiers" are not separated in this notation and
left up to languages, they must be whitespace-separated:

- -- --- + ++ +++ = == === ; Distinct operators.
one+two                    ; Invalid, doesn't parse.
one + two                  ; Valid.
10+20+20                   ; Invalid, doesn't parse.
10 + 20 + 30               ; Valid.
;;

;;
## Blocks

The base notation supports () [] {}, which are parsed as arbitrary sequences.
There are no special rules about their content. Languages defined in terms of
this notation may interpret them as specific data structures and impose their
own rules, such as using only one pair of delimiters.

That said, {} is generally intended for dicts / maps / structs.
;;
() [] {}
([10 "20"] {30 "40" (blah)})

;;
## Calling

The base data notation doesn't define a notation for function calls.
Languages are free to choose their own. The syntax highlighting for this
format should not attempt to detect "calls", leaving this to specific
languages.

That said, the actual language does have a specific call notation.
See `./lang.md`.
;;

;; Dot-based unary call notation: ;;
some_func.some_arg

;; Infix call: ;;
10 + 20

;; Outside-block call notation: ;;
some_func(arg arg arg)
some_func[arg arg arg]
some_func{arg arg arg}

;; Inside-block call notation: ;;
(some_func arg arg arg)
[some_func arg arg arg]
{some_func arg arg arg}

;; Explicit postfix call notation: ;;
some_func: arg arg arg
some_func! arg arg arg

;; Implicit prefix call notation: ;;
some_func arg arg arg

;; A language may require operators to follow the function call notation: ;;
+(10 20 30)
[+ 10 20 30]
+ : 10 20 30

;;
A language is free to define operators as prefix, infix, or postfix,
with its own precedence and grouping rules.
;;
10 + 20 - 30
@ref += 10

;;
Because this notation doesn't support commas and discourages unnecessary
punctuation, unary operators might require grouping to disambiguate them from
binary infix:
;;
10 - (- 20)

;;
## Serialization

This notation can be specialized to describe simple data, like JSON,
by treating `{}` as dicts and providing `nil` `false` `true`.
This should be used for config files.
;;
nil
false
true
[10 20 30]
["value0" "value1" "value2"]
{"key0" 10 "key1" 20 "key2" 30}

;;
However, it's much more flexible than that.

JSON is self-describing for dynamic languages when using a small number of
built-in types. For typed languages, JSON is not self-describing, and lacks
the fluency to annotate values with types.

This notation can be specialized to represent arbitrary types by using a
"call" / "constructor" convention. This allows a much richer set of types
compared to JSON. In this sense, our notation is closer to XML than JSON. But
compared to XML, it's MUCH easier to write and read, and has a richer set of
primitive building blocks, not just strings.

Example of such specialization below. Rust users may spot a similarity to RON,
but this notation is lighter because it avoids `:` and `,`.
;;

SomeStructType{
  some_field    `some_value`
  another_field AnotherType[10 20 30]
}

;;
A specialization could also have implicit default types for some structures,
allowing to omit type specifiers:
;;

;; Various ways to represent lists ;;
["value0" "value1" "value2"]
List["value0" "value1" "value2"]
[List "value0" "value1" "value2"]
:["value0" "value1" "value2"]
[: "value0" "value1" "value2"]

;; Various ways to represent sets ;;
("value0" "value1" "value2")
Set("value0" "value1" "value2")
(Set "value0" "value1" "value2")

;; Various ways to represent dicts ;;
{"key0" 123 "key1" 456 "key2" 789}
Dict{"key0" 123 "key1" 456 "key2" 789}
::{"key0" 123 "key1" 456 "key2" 789}

;; Datetime ;;
Time("1234-12-34T01:02:03Z")

;; XML ;;
html[
  body[
    {attr0 "value0" attr1 123}

    span[
      {attr2 "value2" data-attr 456}

      namespace:element["text_node"]
    ]
  ]
]
